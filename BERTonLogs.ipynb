{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMjnCtpz+6h+ImQNH2aGBVL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Vergosss/Thesis/blob/main/BERTonLogs.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "WAsJPxSdeM6-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 767
        },
        "outputId": "3d5f8b47-5382-4512-9b2b-ea69655f9f2a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "cpu\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>BlockId</th>\n",
              "      <th>Label</th>\n",
              "      <th>Features</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>516115</th>\n",
              "      <td>blk_1284565931929274189</td>\n",
              "      <td>1</td>\n",
              "      <td>[E5,E5,E22,E5,E11,E9,E11,E9,E11,E9,E26,E26,E26]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>101511</th>\n",
              "      <td>blk_1635535449182148112</td>\n",
              "      <td>1</td>\n",
              "      <td>[E22,E5,E5,E5,E26,E26,E11,E9,E11,E9,E11,E9,E26,E3,E4,E3,E3,E4,E3,E4,E3,E3,E23,E23,E23,E21,E21,E21]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>453170</th>\n",
              "      <td>blk_-4608184688522533148</td>\n",
              "      <td>1</td>\n",
              "      <td>[E5,E22,E5,E5,E11,E9,E11,E9,E26,E26,E11,E9,E26,E23,E23,E23,E21,E21,E21]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>280163</th>\n",
              "      <td>blk_-1056953407029441240</td>\n",
              "      <td>1</td>\n",
              "      <td>[E5,E5,E22,E5,E11,E9,E11,E9,E11,E9,E26,E26,E26,E23,E23,E23,E21,E21,E21]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>550118</th>\n",
              "      <td>blk_-4200477860243797036</td>\n",
              "      <td>1</td>\n",
              "      <td>[E5,E22,E5,E5,E11,E9,E11,E9,E26,E26,E11,E9,E26,E23,E23,E23,E21,E21,E21]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>EventId</th>\n",
              "      <th>EventTemplate</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>E29</td>\n",
              "      <td>[*]PendingReplicationMonitor timed out block[*]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>E16</td>\n",
              "      <td>[*]:Transmitted block[*]to[*]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>E18</td>\n",
              "      <td>[*]Starting thread to transfer block[*]to[*]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>E21</td>\n",
              "      <td>[*]Deleting block[*]file[*]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>E13</td>\n",
              "      <td>[*]Receiving empty packet for block[*]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'E1': '[*]Adding an already existing block[*]', 'E2': '[*]Verification succeeded for[*]', 'E3': '[*]Served block[*]to[*]', 'E4': '[*]Got exception while serving[*]to[*]', 'E5': '[*]Receiving block[*]src:[*]dest:[*]', 'E6': '[*]Received block[*]src:[*]dest:[*]of size[*]', 'E7': '[*]writeBlock[*]received exception[*]', 'E8': '[*]PacketResponder[*]for block[*]Interrupted[*]', 'E9': '[*]Received block[*]of size[*]from[*]', 'E10': '[*]PacketResponder[*]Exception[*]', 'E11': '[*]PacketResponder[*]for block[*]terminating[*]', 'E12': '[*]:Exception writing block[*]to mirror[*]', 'E13': '[*]Receiving empty packet for block[*]', 'E14': '[*]Exception in receiveBlock for block[*]', 'E15': '[*]Changing block file offset of block[*]from[*]to[*]meta file offset to[*]', 'E16': '[*]:Transmitted block[*]to[*]', 'E17': '[*]:Failed to transfer[*]to[*]got[*]', 'E18': '[*]Starting thread to transfer block[*]to[*]', 'E19': '[*]Reopen Block[*]', 'E20': '[*]Unexpected error trying to delete block[*]BlockInfo not found in volumeMap[*]', 'E21': '[*]Deleting block[*]file[*]', 'E22': '[*]BLOCK* NameSystem[*]allocateBlock:[*]', 'E23': '[*]BLOCK* NameSystem[*]delete:[*]is added to invalidSet of[*]', 'E24': '[*]BLOCK* Removing block[*]from neededReplications as it does not belong to any file[*]', 'E25': '[*]BLOCK* ask[*]to replicate[*]to[*]', 'E26': '[*]BLOCK* NameSystem[*]addStoredBlock: blockMap updated:[*]is added to[*]size[*]', 'E27': '[*]BLOCK* NameSystem[*]addStoredBlock: Redundant addStoredBlock request received for[*]on[*]size[*]', 'E28': '[*]BLOCK* NameSystem[*]addStoredBlock: addStoredBlock request received for[*]on[*]size[*]But it does not belong to any file[*]', 'E29': '[*]PendingReplicationMonitor timed out block[*]'}\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>BlockId</th>\n",
              "      <th>Label</th>\n",
              "      <th>Features</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>185616</th>\n",
              "      <td>blk_-2112657751470458754</td>\n",
              "      <td>1</td>\n",
              "      <td>[[, E, 5, ,, E, 5, ,, E, 5, ,, E, 2, 2, ,, E, 1, 1, ,, E, 9, ,, E, 1, 1, ,, E, 9, ,, E, 1, 1, ,, E, 9, ,, E, 2, 6, ,, E, 2, 6, ,, E, 2, 6, ,, E, 2, 3, ,, E, 2, 3, ,, E, 2, 3, ,, E, 2, 1, ,, E, 2, 1, ,, E, 2, 1, ]]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "TrainingArguments.__init__() missing 1 required positional argument: 'output_dir'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-3755ca65a10b>\u001b[0m in \u001b[0;36m<cell line: 79>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBertForSequenceClassification\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"bert-base-uncased\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnum_labels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#modelo me ena extra layer gia to classification\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[0;31m###\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m training_arguments = TrainingArguments(\n\u001b[0m\u001b[1;32m     80\u001b[0m     \u001b[0mevaluation_strategy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"epoch\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m     \u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2e-5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: TrainingArguments.__init__() missing 1 required positional argument: 'output_dir'"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from IPython.display import display, HTML\n",
        "from transformers import BertTokenizer,BertForSequenceClassification,Trainer,TrainingArguments\n",
        "import torch\n",
        "from sklearn.model_selection import train_test_split\n",
        "##\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "##\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)\n",
        "#event vectors\n",
        "event_traces = pd.read_csv('/content/drive/MyDrive/Data/Event_traces.csv',usecols=['BlockId','Label','Features'])\n",
        "event_traces['Label'] = event_traces['Label'].map({'Success':1,'Fail':0})\n",
        "#event template- message\n",
        "log_templates = pd.read_csv('/content/drive/MyDrive/Data/HDFS.log_templates.csv')\n",
        "#Printing-Displaying\n",
        "display(HTML((event_traces.sample(5)).to_html()))\n",
        "#\n",
        "display(HTML((log_templates.sample(5)).to_html()))\n",
        "##Dictionary ton EventIds-Events\n",
        "event_dictionary = dict(zip(log_templates['EventId'],log_templates['EventTemplate']))\n",
        "\n",
        "print(event_dictionary)\n",
        "##\n",
        "def features_to_strings(entry):\n",
        "  return [event_dictionary.get(eventID,eventID) for eventID in entry['Features']]\n",
        "###apply to every row in the dataset\n",
        "event_traces['Features']\n",
        "event_traces['Features'] = event_traces.apply(features_to_strings,axis=1)\n",
        "display(HTML((event_traces.sample(1)).to_html()))\n",
        "\n",
        "##\n",
        "'''\n",
        "#\n",
        "logs_csv = pd.read_csv('/content/drive/MyDrive/Data/BGL.csv')\n",
        "#print('First 5 entries: ',logs_csv.head())\n",
        "display(HTML((logs_csv.sample(5)).to_html()))\n",
        "##\n",
        "#print('Last 5 entries: ',logs_csv.tail())\n",
        "labels = logs_csv['Label'].unique()\n",
        "print(labels)\n",
        "#\n",
        "logs_csv['Label'] = logs_csv['Label'].map({'-':0})\n",
        "logs_csv['Label'] = logs_csv['Label'].fillna(1).astype(int)\n",
        "#\n",
        "display(HTML((logs_csv.sample(5)).to_html()))\n",
        "###\n",
        "print(logs_csv['Label'].value_counts())\n",
        "\n",
        "\n",
        "'''\n",
        "##\n",
        "\n",
        "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\") # tokenizer\n",
        "#orisma ena line tou dataset opote epilego to column me to keimeno pou thelo na tokenaro\n",
        "def tokenize_logs(entry):\n",
        "  return tokenizer(entry['Content'],padding='max_length',truncation=True)\n",
        "#\n",
        "'''\n",
        "logs_csv['Content'] = logs_csv.apply(tokenize_logs,axis=1)\n",
        "#\n",
        "\n",
        "#\n",
        "display(HTML((logs_csv.sample(5)).to_html()))\n",
        "##\n",
        "drop_columns = ['LineId','Timestamp','Date','Node','Time','NodeRepeat','Type','Component','Level','EventId','EventTemplate']\n",
        "clean_logs_csv = logs_csv.drop(columns=drop_columns)\n",
        "display(HTML((clean_logs_csv.sample(5)).to_html()))\n",
        "'''\n",
        "##\n",
        "#X_train,X_test,y_train,y_test = train_test_split(clean_logs_csv['Content'],clean_logs_csv['Label'],test_size=0.2,random_state=42)\n",
        "#print(X_train[0])\n",
        "#########Fine tuning meso ton parakato parametron##########\n",
        "\n",
        "model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\",num_labels=2).to(device)#modelo me ena extra layer gia to classification\n",
        "###\n",
        "training_arguments = TrainingArguments(\n",
        "    evaluation_strategy = \"epoch\",\n",
        "    learning_rate=2e-5,\n",
        "     per_device_train_batch_size=16,\n",
        "    per_device_eval_batch_size=64\n",
        "\n",
        ")\n",
        "\n",
        "#########\n",
        "trainer = Trainer(\n",
        "\n",
        "    model=model,#modelo pou tha kanei to classification,\n",
        "\n",
        "    args=training_args,\n",
        "    tokenizer=tokenizer#o tokenizer,\n",
        "\n",
        "    #data_collator=data_collator,\n",
        "\n",
        ")\n",
        "### Train the model\n",
        "#trainer.train()\n"
      ]
    }
  ]
}