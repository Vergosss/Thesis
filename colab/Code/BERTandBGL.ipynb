{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"14O_JiNZxX9GhGYGuU1MwDJ36KdsaqMgy","timestamp":1734195069774}]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"r6JUdHZ9n3S-","outputId":"a16ab2ed-682f-45d5-d064-019e862d1b21","executionInfo":{"status":"error","timestamp":1735432311054,"user_tz":-120,"elapsed":371172,"user":{"displayName":"TheTrickster","userId":"16303796985891777880"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting datasets\n","  Downloading datasets-3.2.0-py3-none-any.whl.metadata (20 kB)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.16.1)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.26.4)\n","Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (17.0.0)\n","Collecting dill<0.3.9,>=0.3.0 (from datasets)\n","  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.2.2)\n","Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.32.3)\n","Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.67.1)\n","Collecting xxhash (from datasets)\n","  Downloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n","Collecting multiprocess<0.70.17 (from datasets)\n","  Downloading multiprocess-0.70.16-py310-none-any.whl.metadata (7.2 kB)\n","Collecting fsspec<=2024.9.0,>=2023.1.0 (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets)\n","  Downloading fsspec-2024.9.0-py3-none-any.whl.metadata (11 kB)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.11.10)\n","Requirement already satisfied: huggingface-hub>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.27.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.2)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.2)\n","Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.4.4)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.2)\n","Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (24.3.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.5.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.1.0)\n","Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (0.2.1)\n","Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.18.3)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.23.0->datasets) (4.12.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.4.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2.2.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2024.12.14)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n","Downloading datasets-3.2.0-py3-none-any.whl (480 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m480.6/480.6 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading fsspec-2024.9.0-py3-none-any.whl (179 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m179.3/179.3 kB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m14.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: xxhash, fsspec, dill, multiprocess, datasets\n","  Attempting uninstall: fsspec\n","    Found existing installation: fsspec 2024.10.0\n","    Uninstalling fsspec-2024.10.0:\n","      Successfully uninstalled fsspec-2024.10.0\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","gcsfs 2024.10.0 requires fsspec==2024.10.0, but you have fsspec 2024.9.0 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed datasets-3.2.0 dill-0.3.8 fsspec-2024.9.0 multiprocess-0.70.16 xxhash-3.5.0\n","Collecting evaluate\n","  Downloading evaluate-0.4.3-py3-none-any.whl.metadata (9.2 kB)\n","Requirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (3.2.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from evaluate) (1.26.4)\n","Requirement already satisfied: dill in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.3.8)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from evaluate) (2.2.2)\n","Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (2.32.3)\n","Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from evaluate) (4.67.1)\n","Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from evaluate) (3.5.0)\n","Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.70.16)\n","Requirement already satisfied: fsspec>=2021.05.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (2024.9.0)\n","Requirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.27.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from evaluate) (24.2)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (3.16.1)\n","Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (17.0.0)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (3.11.10)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (6.0.2)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.12.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (3.4.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (2.2.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (2024.12.14)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2024.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2024.2)\n","Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (2.4.4)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.2)\n","Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.3)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (24.3.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.5.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.1.0)\n","Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (0.2.1)\n","Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.18.3)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.17.0)\n","Downloading evaluate-0.4.3-py3-none-any.whl (84 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.0/84.0 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: evaluate\n","Successfully installed evaluate-0.4.3\n","torch version 2.5.1+cu121\n","pandas version 2.2.2\n","numpy version 1.26.4\n","scipy version 4.47.1\n","1.13.1\n","WAIT\n","Mounted at /content/drive\n","cpu\n","[{'Label': '-', 'Timestamp': '1117838570', 'Date': '2005.06.03', 'Node': 'R02-M1-N0-C:J12-U11', 'Time': '2005-06-03-15.42.50.363779', 'NodeRepeat': 'R02-M1-N0-C:J12-U11', 'Type': 'RAS', 'Component': 'KERNEL', 'Level': 'INFO', 'Content': 'instruction cache parity error corrected'}, {'Label': '-', 'Timestamp': '1117838570', 'Date': '2005.06.03', 'Node': 'R02-M1-N0-C:J12-U11', 'Time': '2005-06-03-15.42.50.527847', 'NodeRepeat': 'R02-M1-N0-C:J12-U11', 'Type': 'RAS', 'Component': 'KERNEL', 'Level': 'INFO', 'Content': 'instruction cache parity error corrected'}]\n","Class Distribution before sampling:  Label\n","-            4283439\n","KERNDTLB      152734\n","KERNSTOR       63491\n","APPSEV         49651\n","KERNMNTF       31531\n","KERNTERM       23338\n","KERNREC         6145\n","APPREAD         5983\n","KERNRTSP        3983\n","APPRES          2370\n","APPUNAV         2048\n","APPTO           1991\n","KERNMICRO       1503\n","APPOUT           816\n","KERNMNT          720\n","APPBUSY          512\n","KERNMC           342\n","APPCHILD         320\n","KERNSOCK         209\n","LINKIAP          166\n","APPALLOC         144\n","KERNSERV          62\n","LINKDISC          24\n","KERNPAN           18\n","KERNCON           16\n","LINKPAP           14\n","KERNNOETH         14\n","MONPOW            12\n","APPTORUS          10\n","KERNPROG           5\n","KERNFLOAT          3\n","KERNRTSA           3\n","MMCS               3\n","MONNULL            2\n","LINKBLL            2\n","KERNEXT            1\n","KERNBIT            1\n","MONILL             1\n","KERNTLBE           1\n","Name: count, dtype: int64\n","Class Distribution after sampling:  Label\n","-            428521\n","KERNDTLB      15277\n","KERNSTOR       6213\n","APPSEV         4918\n","KERNMNTF       3153\n","KERNTERM       2334\n","KERNREC         615\n","APPREAD         597\n","KERNRTSP        418\n","APPRES          235\n","APPTO           199\n","APPUNAV         198\n","KERNMICRO       152\n","APPOUT           84\n","KERNMNT          71\n","APPBUSY          52\n","APPCHILD         33\n","KERNMC           23\n","KERNSOCK         21\n","APPALLOC         16\n","LINKIAP          16\n","KERNSERV          6\n","KERNCON           2\n","LINKDISC          2\n","KERNNOETH         2\n","KERNPAN           1\n","KERNFLOAT         1\n","LINKPAP           1\n","MMCS              1\n","MONPOW            1\n","Name: count, dtype: int64\n","Nulls of Content 3440\n","Nulls of Time:  0\n","Nulls of Node:  0\n","Nulls of Node:  0\n","Lines where Node is NULL 0\n","Lines where Node is UNKNOWN_LOCATION 0\n","WAIT\n","Lines where Node is NULL 0\n","Lines where Node is UNKNOWN_LOCATION 0\n","Mean duration of each node:  69.97624601971836\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"Interrupted by user","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-e1a1287bf240>\u001b[0m in \u001b[0;36m<cell line: 121>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m \u001b[0;31m#\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 121\u001b[0;31m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'WAIT'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    122\u001b[0m \u001b[0;31m##GROUPING IN FIXED TIME WINDOWS WITH NODEID AND WINDOW SIZE##\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[0;31m#windows = pd.DataFrame(columns=['Node','Window Start','text','labels'])#ena label column alla ekkremei pos tha ypologistei\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m    849\u001b[0m                 \u001b[0;34m\"raw_input was called, but this frontend does not support input requests.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    850\u001b[0m             )\n\u001b[0;32m--> 851\u001b[0;31m         return self._input_request(str(prompt),\n\u001b[0m\u001b[1;32m    852\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    853\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 895\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Interrupted by user\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    896\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid Message:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"]}],"source":["import re\n","import pandas as pd\n","import numpy as np\n","from IPython.display import display, HTML\n","import transformers\n","from transformers import BertTokenizer,BertForSequenceClassification,Trainer,TrainingArguments\n","from transformers import AutoTokenizer, AutoModelForSequenceClassification\n","from sklearn.preprocessing import LabelEncoder\n","import torch\n","from sklearn.model_selection import train_test_split\n","from google.colab import drive\n","!pip install datasets\n","!pip install evaluate\n","from datasets import Dataset\n","import evaluate\n","import scipy\n","from scipy.special import expit\n","#\n","print('torch version',torch.__version__)\n","print('pandas version',pd.__version__)\n","print('numpy version',np.__version__)\n","print('scipy version',transformers.__version__)\n","print(scipy.__version__)\n","input('WAIT')\n","drive.mount('/content/drive')\n","##\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","print(device)\n","#####PREPROCESSING####\n","#read file lines\n","\n","with open('/content/drive/MyDrive/Data/BGL.log','r') as file:\n","  lines = file.readlines()#perno tis grammes tou arxeiou\n","  lines = [line.strip() for line in lines]#list comprehension gia an vgalo ta newlines\n","###\n","log_templates = pd.read_csv('/content/drive/MyDrive/Data/BGL_templates.csv')\n","\n","##\n","part = r\"(?P<Label>.+)\\s(?P<Timestamp>\\d{10})\\s(?P<Date>\\d{4}\\.\\d{2}\\.\\d{2})\\s(?P<Node>\\S+)\\s(?P<Time>\\S+)\\s(?P<NodeRepeat>\\S+)\\s(?P<Type>\\S+)\\s(?P<Component>\\S+)\\s(?P<Level>\\S+)\"\n","regex = rf\"{part}(\\s(?P<Content>.+))?\"\n","#to f gia antikatastasi {variable}\n","#\n","#list comprehension - vazo me ayth th texniki se mia lista to dictionary pou prokyptei apo ta matches kai tis antistixiseis tous sta groups\n","lines = [(re.match(regex,line)).groupdict() for line in lines]\n","\n","print(lines[0:2])\n","#To dataframe\n","logs = pd.DataFrame.from_dict(lines)\n","#display(HTML((logs.sample(1)).to_html()))\n","####\n","\n","#logs = pd.read_csv('/content/drive/MyDrive/Data/BGL_2k.log_structured.csv')\n","\n","###CONVERT TO DATETIME####\n","logs['Time'] = pd.to_datetime(logs['Time'],format=\"%Y-%m-%d-%H.%M.%S.%f\")\n","#drop useless columns\n","logs.drop(columns=['Timestamp','Date','NodeRepeat','Type','Component','Level'],inplace=True)\n","##NO NULL VALUES\n","logs = logs[(logs['Node'] != 'NULL') & (logs['Node'] != 'UNKNOWN_LOCATION')]\n","#\n","\n","###SAMPLE EVERY NTH ROWS#####\n","print('Class Distribution before sampling: ',logs['Label'].value_counts())\n","\n","logs = logs.iloc[::10]#px kathe 10 deigmata pare +1 deigma\n","#########\n","print('Class Distribution after sampling: ',logs['Label'].value_counts())\n","print('Nulls of Content',logs['Content'].isnull().sum())\n","print('Nulls of Time: ',logs['Time'].isnull().sum())\n","#\n","print('Nulls of Node: ',logs['Node'].isnull().sum())\n","#\n","logs['Node'] = logs['Node'].fillna('NULL')\n","\n","#\n","print('Nulls of Node: ',logs['Node'].isnull().sum())\n","\n","#\n","print('Lines where Node is NULL',logs['Node'].value_counts().get('NULL',0))\n","print('Lines where Node is UNKNOWN_LOCATION',logs['Node'].value_counts().get('UNKNOWN_LOCATION',0))\n","##MPORO NA RIKSO KAI TA LINES ME NULL NODES H UNKNOWN LOCATION EFOSON STO UNKNOWN LOCATION MPOREI\n","#NA ANAFERETAI SE DIAFORETIKA NODES EN TELEI ARA DEN SXETIZONTAI NO CONTEXT H KAI OXI\n","#print('Random null content row: ',(logs[logs['Content'].isnull()]).sample(1))\n","##\n","#display(HTML(((logs[logs['Content'].isnull()]).sample(1)).to_html()))\n","input('WAIT')\n","###Fill None Content with empty string or drop them(de tha to proteina-alla meionei ton ogko ton dedomenon)##\n","logs['Content'] = logs['Content'].fillna('')\n","##Drop unknown nodes or null nodes###\n","#\n","print('Lines where Node is NULL',logs['Node'].value_counts().get('NULL',0))\n","print('Lines where Node is UNKNOWN_LOCATION',logs['Node'].value_counts().get('UNKNOWN_LOCATION',0))\n","###\n","#####\n","##\n","##CLASS/LABELS ENCODING######\n","##\n","'''\n","encoder = LabelEncoder()\n","logs['Label'] = encoder.fit_transform(logs['Label'])\n","'''\n","#############################\n","logs.to_csv('/content/drive/MyDrive/Saves/logs.csv')\n","logs = logs.sort_values(by=['Node','Time']).groupby('Node',dropna=False)#sortare vash nodeid kai meta xronou oste kathe group na einai xronika sortarismeno kai meta groupare ta vash nodeID\n","#\n","ranges = logs.agg(MinTime=('Time', 'min'),MaxTime=('Time', 'max'))\n","ranges['TimeRangeDays'] = (ranges['MaxTime'] - ranges['MinTime']).dt.days\n","print('Mean duration of each node: ',ranges['TimeRangeDays'].mean())\n","##An deigmatolipto omoiomorfa ana 10 deigmata->meso duration / group = 70 meres\n","#an einai to bgl_2k -> xoris deigmatolipsia einai 1.6 meres / group meso oro\n","#an einai bgl_2k -> me deigmatolipsia 0.3 meres / group meso oro\n","#an einai kanoniko xoris deigmatolipsia >>> meres 170 kati / group meso oro\n","'''\n","_,first_group = list(logs)[0]\n","print(first_group.empty)\n","first_group = pd.DataFrame(first_group)\n","print(' duration of Node : R02-M1-N0-C:J12-U11',(first_group['Time'].max() - first_group['Time'].min()).days)\n","'''\n","\n","#\n","input('WAIT')\n","##GROUPING IN FIXED TIME WINDOWS WITH NODEID AND WINDOW SIZE##\n","#windows = pd.DataFrame(columns=['Node','Window Start','text','labels'])#ena label column alla ekkremei pos tha ypologistei\n","WINDOW_SIZE = \"1h\" ####VARIABLE\n","ANOMALY_PERCENTAGE = 0.01\n","windows = []\n","#########\n","def create_time_windows(group):\n","  global windows\n","\n","  #vale sto windows dataframe to id tou node os mia stili,allh stili to start tou window, sthlh text combined ola ta content tou xronikou group/>se deyterh fash to label\n","  #enose ola ta content tou time window se mia log paragraph\n","  #\n","  ##\n","  time_windows = group.groupby(pd.Grouper(key='Time',freq=\"1W\",label='left'))#ftiakse ta parathyra aytou tou node\n","  #ena groupby object einai ena tuple ID-Data ego xrhsimopoio ta data\n","  for start,subgroup in time_windows:#ena grouby object epistrefei ena tuple tou typou (id,data) xrhsimopoio ta data kai to id paei axrisimopoihto\n","    #joinare ola ta strings tou subgroup kai valta sto neo dataframe\n","    text = (' '.join(subgroup['Content']).strip())#strip kostizei\n","    node_name = group.name\n","    #window_start = subgroup['Time'].min()\n","    window_start = start\n","    #\n","    #EXO PROVLIMA AN EXO ADEIA GROUPS->AXRISTA DEN PROSFEROUN PLIROFORIA-CLASSIFICATION-SYSXETISEIS->PIO POLLA MHDENIKA->PIO MEGALO IMBALANCE->XEIROTERH APODOSH->DIVISION/0 ERROR\n","    labels = 0\n","    if len(subgroup) == 0:\n","      continue#axristo group\n","    else:\n","      #anomaly_percentage = len(subgroup[subgroup['Label'] != '-']) / len(subgroup['Label'])\n","      #labels = 1 if anomaly_percentage > ANOMALY_PERCENTAGE else 0\n","      labels = 1 if len(subgroup[subgroup['Label'] != '-']) > 0 else 0 #1vs ALL\n","\n","    data = {'Node': node_name, 'Window Start': window_start,'text': text,'labels':labels}  # ta [] ta thelei alios peta error kati gia scalar values\n","    #windows = pd.concat([windows, data]) -->>OXIIII PIANEI PARA POLLH MNHMH MH APODOTIKO\n","    #vale os window start h to key tou subgroup h to min ton datetimes tou group\n","    #vale os nodeid to group.name\n","    windows.append(data)\n","  #\n","  ##\n","  return\n","######APPLY THE FUNCTION TO THE LOGS#######\n","######TO PARATHYRO PREPEI NA PAREI KAI KAPOIO LABEL MPORO PX ME DIAFOROUS TROPOUS\n","####EPEIDH EINAI POLLA TA BENIGN GIA KALYTERO BALANCE THA MPOROUSA PX AKOMA KAI\n","###ENA ALLO LABEL NA YPARXEI STO GROUP PERA TOU BENIGN NA TO THEORISO ANOMALY\n","###H ME KAPOIO THRESHOLD TON MH BENIGN KAI PANO NA THEOREITAI ANOMALY\n","logs.apply(create_time_windows)\n","###\n","windows = pd.DataFrame(windows)\n","windows.info()\n","print('Distribution of classes',windows['labels'].value_counts())\n","##SAVING TO CSV#\n","\n","windows.to_csv('/content/drive/MyDrive/Saves/windows.csv')\n","##\n"]},{"cell_type":"code","source":[],"metadata":{"id":"wCuioAzSPmO6"},"execution_count":null,"outputs":[]}]}